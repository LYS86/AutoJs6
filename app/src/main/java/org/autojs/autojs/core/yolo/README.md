# 模型输入

yolo8到yolo11输入形状都是 [1, 640, 640, 3]

- 输入形状： [1, 640, 640, 3]
- 1 代表批次大小（batch size），即每次输入到模型的图像数量，这里为1张图像。
- 640, 640 代表图像的宽度和高度，单位是像素，这里指定为640x640像素，是YOLO模型常用的输入尺寸
- 3 代表图像的颜色通道数，即RGB三通道。

# 模型输出

## YOLOv10

1. **输出格式**：YOLOv10模型的输出形状为[1, 300, 6]，其中300指的是预测框的数目，6分别代表：x1, y1, x2, y2, score, classid。这意味着每个预测框由六个值组成，分别对应左上角和右下角的坐标、置信度和类别ID。

2. **无需NMS**：与之前的YOLO版本不同，YOLOv10模型不需要非极大值抑制（NMS）处理，因为它直接输出最终的预测结果。

## YOLOv8、YOLOv9和YOLOv11

YOLOv8、YOLOv9和YOLOv11模型的输出格式是相同的，都是(1, 84, 8400)

1. **输出形状**：YOLOv8模型的输出形状为(1, 84, 8400)。这个形状可以解释为：1代表批次大小（batch size），84代表每个预测框的输出维度（包括4个边界框预测值和80个类别概率），8400是不同尺度输出特征图叠加的结果。

2. **边界框预测值**：在84维的输出中，前4个值是边界框的预测值，通常表示为xywh格式，即中心点坐标(x, y)和宽度(w)、高度(h)。

3. **类别概率**：剩下的80个值是类别概率，表示模型对于每个边界框预测属于80个不同类别的概率。

4. **置信度**：YOLOv8不另外对置信度进行预测，而是采用类别里面最大的概率作为置信度（score）。

5. **特征图叠加**：8400是模型各尺度输出特征图叠加之后的结果，具体如何叠加可以查看源码，但在一般推理中不需要关注这一点。

6. **后处理**：模型的输出需要经过后处理，将(1, 84, 8400)处理成(8400, 85)，其中85=box:4 + conf:1 + cls:80，即每个特征图的cell包含4个预测框坐标、1个置信度（最大类别概率）和80个类别概率。
7. **输出形状**  当输入形状为[1, 640, 640, 3],输出形状为[1, 84, 8400],当输入形状为[1, 320, 320, 3]，输出形状为[1, 84, 2100]

# 已知问题

1.yolo10，yolo11，不能使用gpu推理。